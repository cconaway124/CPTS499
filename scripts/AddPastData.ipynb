{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPTS 499\n",
    "\n",
    "## Adding on past data to the dataframe (NO2, Ozone, Lead, CO, SO2, and some others)\n",
    "\n",
    "## To use this script:\n",
    "\n",
    "You need to first signup with AirData. They provide you with a key and email. It is a unique way to sign up. [Here it is](https://aqs.epa.gov/aqsweb/documents/data_api.html#signup).\n",
    "\n",
    "With that done, you need to configure a `config.json` file, and set the `CONFIG_TO_JSON` path in the constants tab. The json file should look like:\n",
    "\n",
    "```json\n",
    "{\n",
    "    ...\n",
    "    \"aqs_data\" : {\n",
    "        \"email\": \"<your email here>\",\n",
    "        \"key\": \"<your key here>\"\n",
    "    }\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "The next thing to consider is the `PATH_TO_CSV` in the constants tab. Make that the path to your CSV folder.\n",
    "\n",
    "## Tips:\n",
    "\n",
    "In the constants tab, you will see three variable: `PARTICULATE_MATTER`, `LONGITUDE_RANGE`, `LATITTUDE_RANGE`. These three are configurable value also. If you want more parameters for your data, visit [this link](https://aqs.epa.gov/aqsweb/documents/codetables/parameter_classes.html) to find more available data.\n",
    "\n",
    "The latitude and longitude range is wide because some of these measurements are harder to find. Therefore, we make a larger box to ensure we find something for it.\n",
    "\n",
    "The endpoint we call is set by box. You can either give the `GetAirData` just the latitude and longitude you want, or you can give it a min and max latitude and longitude. To use the latter option, the code would have to be a changed a little, as this reads the location from the CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: haversine in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (2.8.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# install new dependcies\n",
    "%pip install haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import requests as req\n",
    "import json\n",
    "import math\n",
    "from collections import Counter as ct\n",
    "import haversine as hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "DATE_FORMAT = \"%Y-%m-%d\"\n",
    "PATH_TO_CSV = \"../gsur23013.csv\"\n",
    "PATH_TO_CONFIG = \"../config.json\"\n",
    "AQS_DATA = {}\n",
    "with open(PATH_TO_CONFIG, \"r\") as f:\n",
    "        AQS_DATA = json.load(f)[\"aqs_data\"]\n",
    "\n",
    "# this url retrieves the daily data from the AirData services\n",
    "# example: https://aqs.epa.gov/data/api/dailyData/byBox?email=your_email@email.com&key=you_key&param=44201,42101&bdate=20150501&edate=20150502&minlat=33.3&maxlat=33.6&minlon=-87.0&maxlon=-86.7\n",
    "# for the query parameter \"parameter\", you can pass a comma-seperated list it to retrieve multiple different particulate matters. See the dictionary defined below\n",
    "REQUEST_URL = \"https://aqs.epa.gov/data/api/dailyData/byBox?email={}&key={}&param={}&bdate={}&edate={}&minlat={}&maxlat={}&minlon={}&maxlon={}\"\n",
    "\n",
    "PARTICULATE_MATTERS = {\n",
    "        \"Ozone\" : 44201, \n",
    "        \"Lead (TSP) LC\" : 14129,\n",
    "        \"CO\" : 42101,\n",
    "        \"SO2\" : 42401,\n",
    "        \"NO2\" : 42602,\n",
    "        \"PM10 Total 0-10um STP\" : 81102,\n",
    "        \"Lead PM10 LC FRM/FEM\" : 85129,\n",
    "        \"PM2.5 - Local Conditions\" : 88101,\n",
    "        }\n",
    "\n",
    "LATITUDE_RANGE = 7.0\n",
    "LONGITUDE_RANGE = 7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11404\\4100932290.py:2: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv_data = pd.read_csv(PATH_TO_CSV, nrows=400000, skiprows=[1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stamp                  datetime64[ns]\n",
      "yaw                           float64\n",
      "pitch                         float64\n",
      "roll                          float64\n",
      "rotation_rate_x               float64\n",
      "rotation_rate_y               float64\n",
      "rotation_rate_z               float64\n",
      "user_acceleration_x           float64\n",
      "user_acceleration_y           float64\n",
      "user_acceleration_z           float64\n",
      "latitude                      float64\n",
      "longitude                     float64\n",
      "altitude                      float64\n",
      "course                        float64\n",
      "speed                         float64\n",
      "horizontal_accuracy           float64\n",
      "vertical_accuracy             float64\n",
      "battery_state                  object\n",
      "user_activity_label            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# load the csv and anything else\n",
    "csv_data = pd.read_csv(PATH_TO_CSV, nrows=400000, skiprows=[1])\n",
    "\n",
    "# change stamp column to datetime object\n",
    "\n",
    "# Strip the date from a string\n",
    "# params\n",
    "#   date: the str representation of the date\n",
    "# returns\n",
    "#   a datetime object\n",
    "def GetDate(date: str) -> dt.datetime:\n",
    "    day = str.split(date, \" \")[0]\n",
    "        \n",
    "    # strip out the datetime object .\n",
    "    date = dt.datetime.strptime(day, DATE_FORMAT)\n",
    "    return date\n",
    "\n",
    "# Applies the GetDate function to the entire given series\n",
    "# params\n",
    "#   date: the series to apply the date to\n",
    "# returns\n",
    "#   the changed date column\n",
    "def GetDateSeries(date: pd.Series) -> pd.Series:\n",
    "    return date.apply(GetDate)\n",
    "\n",
    "# change date column to just the day\n",
    "csv_data[\"stamp\"] = GetDateSeries(csv_data[\"stamp\"])\n",
    "\n",
    "csv_data.head(10)\n",
    "print(csv_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the unique dates, and their associated latitude and longitudes\n",
    "# params\n",
    "#    df: The dataframe to get the dates, lat, and long from\n",
    "#    date_col: The title of the date column\n",
    "#    lat_col: The title of the lat column\n",
    "#    long_col: The title of the long column\n",
    "# returns\n",
    "#    a list of tuples, where the first spot is the date, the second the latitude, and the third the longitude\n",
    "def UniqueDates(df: pd.DataFrame, date_col: str, lat_col: str, long_col: str) -> list:\n",
    "    unique_dates = []\n",
    "    last_date = dt.datetime.min\n",
    "    for i in range(len(df)):\n",
    "        date = df.loc[i, date_col]\n",
    "        \n",
    "        # if they aren't equal, add that unique date to the list\n",
    "        #next day\n",
    "        if (date.date() != last_date.date()):\n",
    "            \n",
    "            # get the lat and long\n",
    "            lat = df.loc[i, lat_col]\n",
    "            long = df.loc[i, long_col]\n",
    "            \n",
    "            # if they are nan, move to the next available lat and long\n",
    "            if (math.isnan(lat) or math.isnan(long)):\n",
    "                continue\n",
    "                        \n",
    "            unique_dates.append((date, lat, long))\n",
    "        \n",
    "        last_date = date\n",
    "        \n",
    "    return unique_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the specified data from AirData\n",
    "# params\n",
    "#    email: the dataframe to add the column to\n",
    "#    key: The title of the date column\n",
    "#    start_date: The title of the lat column\n",
    "#    end_date: The title of the long column\n",
    "#    latitude: The desired latitude\n",
    "#    longitude: The desired longitude\n",
    "#    params: The list of integer parameters that specify the type of particulate matter you want returned\n",
    "#    max_latitude: (optional) the max latitude you want to consider \n",
    "#    max_longitude: (optional) the max longitude you want to consider\n",
    "# returns\n",
    "#    a dictionary with the parameter name as the key, and the desired value and date as the value\n",
    "# throws\n",
    "#    a ValueError if the parameter list is longer than 5. AirData only permits 5 params at a time\n",
    "def GetAirData(email: str, key: str, start_date: dt.datetime, end_date: dt.datetime, latitude: float, longitude: float, params: list,\n",
    "               max_latitude: float = 0, max_longitude: float = 0) -> dict:\n",
    "    if (len(params) > 5):\n",
    "        raise ValueError(\"The parameter list can only contain 5 or less parameters\")\n",
    "    \n",
    "    # create a box by adding 3 to the lat and long if they aren't passed\n",
    "    if (max_latitude == 0 and max_longitude == 0):\n",
    "        max_latitude = latitude + (LATITUDE_RANGE / 2)\n",
    "        max_longitude = longitude + (LONGITUDE_RANGE / 2)\n",
    "        latitude -= (LATITUDE_RANGE / 2)\n",
    "        longitude -= (LONGITUDE_RANGE / 2)\n",
    "        \n",
    "        # swap max and min if they are in the wrong spots\n",
    "        if (max_latitude < latitude):\n",
    "            temp = max_latitude\n",
    "            max_latitude = latitude\n",
    "            latitude = temp\n",
    "            \n",
    "        if (max_longitude < longitude):\n",
    "            temp = max_longitude\n",
    "            max_longitude = longitude\n",
    "            longitude = temp\n",
    "            \n",
    "    url = REQUEST_URL.format(email, key, \",\".join(str(x) for x in params), str(start_date.date()).replace(\"-\", \"\"), \n",
    "                             str(end_date.date()).replace(\"-\", \"\"), latitude, max_latitude, longitude, max_longitude)\n",
    "    print(url)\n",
    "    \n",
    "    response = req.get(url)\n",
    "    \n",
    "    if response.ok:\n",
    "        data = response.json()\n",
    "        values = ExtractInfo(data, latitude, longitude, start_date)\n",
    "        return values\n",
    "            \n",
    "    else:\n",
    "        response.raise_for_status()\n",
    "        return None\n",
    "        \n",
    "# Returns a map object that has the distance to the closest stations measurement\n",
    "# params\n",
    "#    locations: The list of locations (the index and latitude and longitude) of the stations\n",
    "#    latitude: the latitude of the measurement of the person\n",
    "#    longitude: the longitude of the measurement of the person\n",
    "# returns\n",
    "#     a map object with the parameter name and location in a tuple\n",
    "# throws\n",
    "def MinimumDistPerLocation(locations: list, latitude: float, longitude: float) -> map:\n",
    "    closest_params = {}\n",
    "    # loop through locations\n",
    "    for i, (lat, long), param in locations:\n",
    "        curr_dist = hs.haversine((latitude, longitude), (lat, long))\n",
    "        \n",
    "        closest_params[param] = closest_params.get(param, []) + [(i, curr_dist)]\n",
    "    # map the dictionary of key: lists to a dict of key:tuple, with the closest station\n",
    "    return map(lambda x: (x, min(closest_params[x], key=lambda y: y[1])), closest_params)\n",
    "\n",
    "# Extract the desired measurement from the given data\n",
    "# params\n",
    "#    data: the dictionary that holds the desired data\n",
    "#    latitude: The desired latitude\n",
    "#    longitude: The desired longitude\n",
    "#    date: the date of the measurement\n",
    "# returns\n",
    "#    a dictionary with the parameter name as the key, and the date and measurement as its value\n",
    "# throws\n",
    "def ExtractInfo(data: dict, latitude: float, longitude: float, date: dt.datetime) -> dict:\n",
    "    print(len(data[\"Data\"]))\n",
    "    if data[\"Header\"][0][\"rows\"] == 0:\n",
    "        print(\"No data returned\")\n",
    "        return\n",
    "    \n",
    "    locations = []\n",
    "    \n",
    "    # loop through each row that was returned\n",
    "    for i, val in enumerate(data[\"Data\"]):\n",
    "        # skip this row if it is not valid\n",
    "        if not val[\"validity_indicator\"] == 'Y':\n",
    "            continue\n",
    "        \n",
    "        locations.append((i, (val[\"latitude\"], val[\"longitude\"]), val[\"parameter\"]))\n",
    "    \n",
    "    # get the closest location for each parameter\n",
    "    closest_params = MinimumDistPerLocation(locations, latitude, longitude)\n",
    "    arithmetic_means = {}\n",
    "    for param, (index, _) in closest_params:\n",
    "        arithmetic_means[param] = (data[\"Data\"][index][\"arithmetic_mean\"], date)\n",
    "        \n",
    "    return arithmetic_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an the desired columns to a new dataframe\n",
    "# params\n",
    "#    df: the dataframe to add the column to\n",
    "#    date_col: The title of the date column\n",
    "#    params: the integer list of parameters to add to the dataframe\n",
    "# returns\n",
    "# throws\n",
    "def AddParametersToData(df: pd.DataFrame, date_col: str, params: list= [PARTICULATE_MATTERS[\"Ozone\"]]) -> pd.DataFrame:\n",
    "    # get the counts of unique dates\n",
    "    number_of_records = ct(df[date_col].astype(str))\n",
    "    \n",
    "    # retrieve the unique dates and their locations\n",
    "    date_and_loc = UniqueDates(csv_data, \"stamp\", \"latitude\", \"longitude\")\n",
    "    new_columns = {}\n",
    "    \n",
    "    # loop through the dates and locations and for each parameter on that day, add list to a dictionary with those values\n",
    "    for date, lat, long in date_and_loc:\n",
    "        values = GetAirData(AQS_DATA[\"email\"], AQS_DATA[\"key\"], date, date, \n",
    "                        lat, long, params)\n",
    "        \n",
    "        for param, (mean, date) in values.items():\n",
    "            new_columns[param] = new_columns.get(param, []) + [mean] * number_of_records[str(date.date())]\n",
    "            \n",
    "    # add column to the new dataframe\n",
    "    new_df = df.copy(deep=True)\n",
    "    for param, value in new_columns.items():\n",
    "        if len(value) == 0:\n",
    "            continue\n",
    "        new_df[param] = value\n",
    "        \n",
    "    return new_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://aqs.epa.gov/data/api/dailyData/byBox?email=chase.conaway@wsu.edu&key=sandwolf12&param=44201,42101,42401,42602,85129&bdate=20230828&edate=20230828&minlat=43.23060607910156&maxlat=50.23060607910156&minlon=-120.67095184326172&maxlon=-113.67095184326172\n",
      "4\n",
      "https://aqs.epa.gov/data/api/dailyData/byBox?email=chase.conaway@wsu.edu&key=sandwolf12&param=44201,42101,42401,42602,85129&bdate=20230829&edate=20230829&minlat=43.24932861328125&maxlat=50.24932861328125&minlon=-120.64724731445312&maxlon=-113.64724731445312\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stamp</th>\n",
       "      <th>yaw</th>\n",
       "      <th>pitch</th>\n",
       "      <th>roll</th>\n",
       "      <th>rotation_rate_x</th>\n",
       "      <th>rotation_rate_y</th>\n",
       "      <th>rotation_rate_z</th>\n",
       "      <th>user_acceleration_x</th>\n",
       "      <th>user_acceleration_y</th>\n",
       "      <th>user_acceleration_z</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>altitude</th>\n",
       "      <th>course</th>\n",
       "      <th>speed</th>\n",
       "      <th>horizontal_accuracy</th>\n",
       "      <th>vertical_accuracy</th>\n",
       "      <th>battery_state</th>\n",
       "      <th>user_activity_label</th>\n",
       "      <th>Ozone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>-0.033335</td>\n",
       "      <td>0.040521</td>\n",
       "      <td>1.376791</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.003458</td>\n",
       "      <td>-0.969708</td>\n",
       "      <td>0.053266</td>\n",
       "      <td>-0.803538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unplugged</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>0.166034</td>\n",
       "      <td>0.051798</td>\n",
       "      <td>-0.922997</td>\n",
       "      <td>-0.002101</td>\n",
       "      <td>-0.001292</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>0.806522</td>\n",
       "      <td>0.064562</td>\n",
       "      <td>-0.393836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unplugged</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>0.911395</td>\n",
       "      <td>-0.037857</td>\n",
       "      <td>0.041807</td>\n",
       "      <td>-0.001991</td>\n",
       "      <td>-0.000616</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>-0.030992</td>\n",
       "      <td>-0.025427</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unplugged</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>0.910933</td>\n",
       "      <td>-0.024698</td>\n",
       "      <td>0.026261</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>-0.015890</td>\n",
       "      <td>-0.014381</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unplugged</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>0.910843</td>\n",
       "      <td>-0.020273</td>\n",
       "      <td>0.021116</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>-0.000706</td>\n",
       "      <td>-0.010780</td>\n",
       "      <td>-0.008126</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unplugged</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>0.910789</td>\n",
       "      <td>-0.018194</td>\n",
       "      <td>0.018532</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.004182</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>-0.008198</td>\n",
       "      <td>-0.004461</td>\n",
       "      <td>0.004790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unplugged</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>0.910780</td>\n",
       "      <td>-0.016943</td>\n",
       "      <td>0.017129</td>\n",
       "      <td>0.002520</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>-0.004354</td>\n",
       "      <td>-0.004689</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unplugged</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>0.910708</td>\n",
       "      <td>-0.016079</td>\n",
       "      <td>0.016075</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>-0.001150</td>\n",
       "      <td>-0.005681</td>\n",
       "      <td>-0.003535</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unplugged</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>0.910740</td>\n",
       "      <td>-0.015435</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>-0.001784</td>\n",
       "      <td>-0.004720</td>\n",
       "      <td>-0.002968</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unplugged</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>0.910719</td>\n",
       "      <td>-0.014973</td>\n",
       "      <td>0.014860</td>\n",
       "      <td>-0.000675</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>-0.003918</td>\n",
       "      <td>-0.002277</td>\n",
       "      <td>0.003302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unplugged</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       stamp       yaw     pitch      roll  rotation_rate_x  rotation_rate_y  \\\n",
       "0 2023-08-28 -0.033335  0.040521  1.376791         0.000530         0.000567   \n",
       "1 2023-08-28  0.166034  0.051798 -0.922997        -0.002101        -0.001292   \n",
       "2 2023-08-28  0.911395 -0.037857  0.041807        -0.001991        -0.000616   \n",
       "3 2023-08-28  0.910933 -0.024698  0.026261         0.002564         0.000466   \n",
       "4 2023-08-28  0.910843 -0.020273  0.021116         0.001488         0.002050   \n",
       "5 2023-08-28  0.910789 -0.018194  0.018532         0.003596         0.004182   \n",
       "6 2023-08-28  0.910780 -0.016943  0.017129         0.002520         0.002087   \n",
       "7 2023-08-28  0.910708 -0.016079  0.016075         0.000699         0.000615   \n",
       "8 2023-08-28  0.910740 -0.015435  0.015343         0.003869         0.001404   \n",
       "9 2023-08-28  0.910719 -0.014973  0.014860        -0.000675         0.000058   \n",
       "\n",
       "   rotation_rate_z  user_acceleration_x  user_acceleration_y  \\\n",
       "0         0.003458            -0.969708             0.053266   \n",
       "1        -0.000076             0.806522             0.064562   \n",
       "2         0.001076            -0.030992            -0.025427   \n",
       "3         0.001712            -0.015890            -0.014381   \n",
       "4        -0.000706            -0.010780            -0.008126   \n",
       "5         0.000568            -0.008198            -0.004461   \n",
       "6         0.000156            -0.004354            -0.004689   \n",
       "7        -0.001150            -0.005681            -0.003535   \n",
       "8        -0.001784            -0.004720            -0.002968   \n",
       "9         0.001115            -0.003918            -0.002277   \n",
       "\n",
       "   user_acceleration_z  latitude  longitude  altitude  course  speed  \\\n",
       "0            -0.803538       NaN        NaN       NaN     NaN    NaN   \n",
       "1            -0.393836       NaN        NaN       NaN     NaN    NaN   \n",
       "2             0.001905       NaN        NaN       NaN     NaN    NaN   \n",
       "3             0.003470       NaN        NaN       NaN     NaN    NaN   \n",
       "4             0.002089       NaN        NaN       NaN     NaN    NaN   \n",
       "5             0.004790       NaN        NaN       NaN     NaN    NaN   \n",
       "6             0.003448       NaN        NaN       NaN     NaN    NaN   \n",
       "7             0.003236       NaN        NaN       NaN     NaN    NaN   \n",
       "8             0.001869       NaN        NaN       NaN     NaN    NaN   \n",
       "9             0.003302       NaN        NaN       NaN     NaN    NaN   \n",
       "\n",
       "   horizontal_accuracy  vertical_accuracy battery_state user_activity_label  \\\n",
       "0                  NaN                NaN     unplugged                 NaN   \n",
       "1                  NaN                NaN     unplugged                 NaN   \n",
       "2                  NaN                NaN     unplugged                 NaN   \n",
       "3                  NaN                NaN     unplugged                 NaN   \n",
       "4                  NaN                NaN     unplugged                 NaN   \n",
       "5                  NaN                NaN     unplugged                 NaN   \n",
       "6                  NaN                NaN     unplugged                 NaN   \n",
       "7                  NaN                NaN     unplugged                 NaN   \n",
       "8                  NaN                NaN     unplugged                 NaN   \n",
       "9                  NaN                NaN     unplugged                 NaN   \n",
       "\n",
       "    Ozone  \n",
       "0  0.0185  \n",
       "1  0.0185  \n",
       "2  0.0185  \n",
       "3  0.0185  \n",
       "4  0.0185  \n",
       "5  0.0185  \n",
       "6  0.0185  \n",
       "7  0.0185  \n",
       "8  0.0185  \n",
       "9  0.0185  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AddParametersToData(csv_data, \"stamp\", [44201, 42101, 42401, 42602, 85129]).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
